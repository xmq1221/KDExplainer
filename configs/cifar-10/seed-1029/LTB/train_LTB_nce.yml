dataset:
    name: CIFAR10
    root:  /nfs/yxy/data/CIFAR10
    img_w: 32
    img_h: 32
    num_classes: 10
    loss_method: nce

training:
    optimizer:
        name: Adam
        # lr: 0.05
        weight_decay: 5.0e-4
        weight_decay_stage2: 5.0e-4
        momentum: 0.9

    lr_global: 5.0e-2
    lr_branch: 1.0e-2
    lr_stage2: 0.05
    
    t: 10
    lr_decay_epochs: [300]
    lr_decay_rate: 0.1
    batch_size: 128
    # test_batch: 128
    num_workers: 8
    # num_workers: 8
    epochs: 300
    init_epoch: 0
    seed: 1029
    save_ep_freq: 50
    print_iter_freq: 100

validation:
    batch_size: 128
    num_workers: 8

model:
    name: TLB
    loss_method: nce
    task: mc
    pretrained: /home/yxy/kaecode3/LTB_kd/log_LTB_s1_nce/ckpt/best.pth
